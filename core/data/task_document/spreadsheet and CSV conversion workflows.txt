name: Spreadsheet and CSV conversion workflows
description: Convert between CSV, XLSX, and other tabular formats and normalize delimiters, encodings, and headers using efficient CLI-based scripts with minimal steps and clear logging.

goal/outcome:
  - One or more input files (e.g., CSV, TSV, XLSX) at {source_path} are converted to the desired target format(s) (e.g., CSV, XLSX) at {output_directory}.
  - Output files use the agreed delimiter (e.g., "," or ";"), encoding (e.g., UTF-8), and header normalization rules (e.g., lowercase, snake_case, trimmed).
  - Column order and row counts are preserved unless the user explicitly requests modifications.
  - A simple log file in the workspace records each file processed, source â†’ target path, detected/used encoding, delimiter, and status.
  - The user receives a concise summary of converted files, formats, and where outputs and logs are stored.

inputs_params:
  - Required: One or more input file paths (e.g., {source_file_1}, {source_file_2}).
  - Required: Target format for each file or a default (e.g., "csv", "xlsx").
  - Required: Output directory {output_directory} where converted files should be written.
  - Optional: Delimiter configuration for text formats:
    - Input delimiter (e.g., ",", ";", "\t") or "auto-detect".
    - Output delimiter for CSV/TSV files.
  - Optional: Encoding configuration:
    - Input encoding (e.g., "utf-8", "latin-1") or "auto-detect".
    - Output encoding (default: "utf-8").
  - Optional: Header normalization rules:
    - Whether to normalize headers (true/false).
    - Style: lowercase, snake_case, trim spaces, replace spaces with underscores, etc.
  - Optional: Row subset filters (e.g., skip header rows beyond the first, drop completely empty rows).
  - Optional: Overwrite policy:
    - Overwrite existing outputs, add suffix (e.g., "_converted"), or skip if exists.
  - Optional: Dry-run flag:
    - Only inspect structure and produce a preview/log of planned conversions without writing output files.

context:
  reasoning:
    - Keep the workflow simple: confirm parameters, run one Python-based conversion script, log results, and summarize back to the user.
    - Use "create and run python script" with base Python plus on-demand installation of minimal packages like pandas and openpyxl if needed to handle CSV/XLSX.
    - For each input:
      - Optionally detect encoding and delimiter (e.g., using chardet-like packages if installed or simple heuristics).
      - Read into a tabular structure (e.g., pandas DataFrame).
      - Apply header normalization rules if requested.
      - Write out to the target format with the requested delimiter and encoding.
    - Handle overwrites simply: either overwrite or generate a new file name with a suffix like "_converted" or "_{target_format}" according to user preference.
    - Use a single script run to process all files in a batch and to create a simple log file.
    - Only introduce dry-run behavior if requested, in which case the script should inspect input files and print/log inferred delimiter, encoding, column count, and a small preview but skip writing outputs.
  deadline: {time_left} left until deadline {deadline}
  definition_of_done(check during final validation step):
    - All input files agreed upon are either:
      - Successfully converted to the requested format(s), or
      - Explicitly skipped with a reason in the log (e.g., unreadable encoding, missing file).
    - Output files exist in {output_directory} with:
      - Correct extension for the target format.
      - Requested delimiter and encoding for text formats.
      - Headers normalized according to the chosen rules.
    - No existing files are overwritten unexpectedly (policy respected).
    - A log file at {log_file_path} lists, at minimum, for each processed file:
      - source_path, target_path, source_format, target_format, status, and any error message.
    - The final message to the user includes:
      - List or count of files processed.
      - Target formats and key normalization choices.
      - Path to the output directory and the log file.
  avoid:
    - Running multiple separate scripts when a single batch script is sufficient.
    - Using GUI mode or manual tools; CLI scripting is enough.
    - Changing data values (beyond encoding/format and header normalization) without explicit user request.
    - Dropping columns or rows silently.
    - Guessing complex transformation rules; stick to encoding, delimiter, and header normalization only unless requested.

steps:
  name: Confirm files, formats, and normalization rules
  description: Ensure all inputs, outputs, and normalization preferences are clearly defined before running conversions.
  action_instruction: >
    Use "send_message" to restate and confirm:
    - Input file paths (e.g., {source_file_1}, {source_file_2}).
    - Target format for each file or a default {target_format} (e.g., "csv", "xlsx").
    - Output directory {output_directory}.
    - Delimiter behavior:
      - Input delimiter: {input_delimiter} or "auto".
      - Output delimiter: {output_delimiter} (if target is CSV/TSV).
    - Encoding behavior:
      - Input encoding: {input_encoding} or "auto".
      - Output encoding: {output_encoding} (default "utf-8").
    - Header normalization rules:
      - normalize_headers: true/false.
      - normalization_style (e.g., lowercase_and_underscores).
    - Overwrite policy for existing outputs (overwrite, add suffix, or skip).
    - Whether they want a dry-run first (inspect only) or proceed directly to conversion.
    Ask the user to correct or fill any missing critical details. If something remains unclear
    (e.g., target format or overwrite behavior), use "send_message" with a focused question.
    Once clarified, send a short "send_message" summarizing the final parameters so they are explicit in the task history.
  validation_instruction: >
    Confirm that:
    - At least one input file path {source_file} is provided.
    - A valid target format (e.g., "csv" or "xlsx") is specified or defaulted.
    - An output directory {output_directory} is chosen.
    - Overwrite policy is defined (if not specified, default to adding a suffix like "_converted").
    If any of these are missing or conflicting, use "send_message" again and only proceed after clear confirmation.

  name: Run batch conversion script (dry-run or actual)
  description: Use a single Python script to read all inputs, optionally detect encoding/delimiters, apply header normalization, and either preview or write outputs and logs.
  action_instruction: >
    Use "create and run python script" with code that:
    - Accepts:
      - A list of input file paths {source_files}.
      - target_format (per-file or default).
      - output_directory {output_directory}.
      - input_delimiter (or "auto").
      - output_delimiter (if target is CSV/TSV).
      - input_encoding (or "auto").
      - output_encoding.
      - header_normalization settings (normalize_headers, normalization_style).
      - overwrite policy ("overwrite", "suffix", "skip").
      - dry_run flag.
      - log file path {log_file_path} (e.g., "conversion_log_{date_time}.csv").
    - For each input file:
      - Verify the file exists; if not, record a log entry with status="missing" and continue.
      - If needed, attempt basic encoding detection when input_encoding == "auto" (e.g., using a small sample and chardet if available; otherwise default to "utf-8" and catch decode errors).
      - If needed, attempt basic delimiter detection when input_delimiter == "auto" for text files (e.g., inspect the first line for common delimiters like ",", ";", "\t").
      - Read the file into a table, for example using pandas:
        - Install minimal dependencies at the top of the script if necessary (e.g., pandas, openpyxl for XLSX).
      - If header normalization is enabled:
        - Clean column names according to normalization_style (e.g., strip, lowercase, replace spaces and special characters with underscores).
      - Construct the target file path in {output_directory}:
        - Use the base name of the source with the new extension for the target format.
        - Apply overwrite policy:
          - "overwrite": allow same name.
          - "suffix": if the file exists, append "_converted" or a numeric suffix.
          - "skip": if the file exists, record status="skipped_existing" and continue.
      - If dry_run is True:
        - Do not write any output files; instead record a log entry with status like "would_convert" and include inferred encoding/delimiter, target path, and preview info (e.g., number of rows/columns).
      - If dry_run is False:
        - Actually write the data to the target format:
          - For CSV/TSV: use the output delimiter and encoding.
          - For XLSX: use a simple single-sheet export.
        - On success, log status="converted".
        - On any exception, catch it, log status="error" with the error message, and continue with the next file.
    - After processing all files:
      - Write/flush the CSV log at {log_file_path}.
      - Print to stdout:
        - Total files processed.
        - Counts of statuses (converted, missing, skipped_existing, would_convert, error).
        - The log file path and output directory.
  validation_instruction: >
    Inspect the output of "create and run python script":
    - Ensure the script finished without an unhandled exception.
    - Confirm that it reports the log file path {log_file_path}.
    - Note the counts per status (converted / would_convert / skipped_existing / missing / error).
    If the script reports that no files were processed successfully (all missing or errors), use "send_message" to explain this briefly
    and ask the user whether to adjust parameters or stop. If it is a dry-run, ask whether to proceed with an actual conversion
    using the same parameters.

  name: (Optional) Execute actual conversion after dry-run
  description: If a dry-run was performed, optionally rerun the same script with dry_run=false to generate real outputs.
  action_instruction: >
    If dry_run was True:
      - Use "send_message" to:
        - Inform the user that the dry-run finished and show a short summary:
          - Files detected.
          - Target formats.
          - Any notable issues.
          - The log file path from the dry-run.
        - Ask whether to proceed with actual conversion using the same settings.
      - If the user confirms:
        - Call "create and run python script" again with dry_run=False and the same parameters.
      - If the user declines:
        - Clarify that no changes were made and proceed to final reporting.
  validation_instruction: >
    For the actual conversion run after a dry-run:
    - Validate the script output as in the previous step.
    - Confirm that at least some files have status="converted" unless the user expected none.
    - If repeated errors occur for all files, explain this to the user and consider stopping instead of retrying multiple times.

  name: Overall validate conversions
  description: Perform a simple final check that conversions and outputs align with the agreed parameters and definition_of_done.
  action_instruction: >
    Use "create and run python script" or "shell view" to quickly inspect the log file {log_file_path}:
    - Count total lines (excluding header if present).
    - Count how many entries have status="converted" (or "would_convert" for a pure dry-run).
    - Count errors and missing/skipped entries.
    - Optionally check that at least one output file exists in {output_directory} when actual conversion was requested.
    Confirm that:
    - The number of entries in the log matches the number of input files attempted.
    - Status distribution matches what the conversion script reported to stdout.
    No extra data validation is needed unless the user explicitly asks for deeper checks.
  # No separate validation_instruction is needed beyond this brief check.

  name: Close task and report to user
  description: Summarize the conversions, present key details about outputs and logs, and mark the task status.
  action_instruction: >
    Use "send_message" to provide a concise summary:
    - Input files processed (list or count).
    - Target format(s) used.
    - Key normalization choices (delimiter, encoding, header normalization).
    - Whether this was a dry-run, an actual conversion, or both (dry-run + commit).
    - Counts:
      - converted (or would_convert),
      - skipped_existing,
      - missing,
      - error.
    - Paths for:
      - Output directory {output_directory}.
      - Log file {log_file_path}.
    If actual conversions completed to a reasonable standard:
      - Call "mark task completed" with a short message referencing the output and log locations.
    If the user chose to stop after a dry-run:
      - Call "mark task cancel" (or complete, depending on your convention) with a note that no files were modified.
    If the task could not be reasonably completed due to repeated errors or missing files:
      - Call "mark task error" with a brief explanation and point to the log file for further inspection.
