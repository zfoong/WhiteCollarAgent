name: File inventory and summary generation
description: Generate a structured list/report of files in a directory tree, including full paths, sizes, and dates, and save it into the agent workspace as a reusable inventory file (e.g., CSV/Markdown/JSON).

goal/outcome:
  - A file inventory report is created in the workspace at {inventory_file_path}, containing at least:
    - full_path
    - file_name
    - extension
    - size_bytes
    - modified_time
  - Optional: a small summary report at {summary_file_path} with totals (file count, total size) and simple breakdowns (e.g., by extension).
  - No files or directories are modified, moved, or deleted during the process.
  - The inventory covers exactly the specified root directory tree(s), respecting any include/exclude rules.
  - The user receives a concise summary message with:
    - root paths analyzed
    - total number of files
    - total size
    - locations of the generated report file(s).

inputs_params:
  - Required: One or more root directory paths, e.g., {root_directory_1}, {root_directory_2}.
  - Required: Output format preference for the inventory report:
    - "csv" (recommended default), or
    - "md" (Markdown table), or
    - "json".
  - Optional: Recursion flag:
    - true: include all subdirectories (default).
    - false: only list files directly under {root_directory}.
  - Optional: Include filters (simple patterns):
    - By extension list (e.g., [".txt", ".csv", ".jpg"]) or
    - Name substrings (e.g., must contain {keyword}).
  - Optional: Exclude filters:
    - Specific subpaths to skip (e.g., {root_directory}\node_modules, {root_directory}\.git).
    - Extensions to ignore (e.g., [".tmp", ".log"]).
  - Optional: Size or age thresholds (for narrowing inventory if user requests):
    - min_size_bytes (e.g., files >= {min_size_bytes}).
    - max_size_bytes.
    - older_than_days / newer_than_days.
  - Optional: Whether to compute simple aggregate statistics (true/false).
  - Optional: Safety cap on number of files to list (e.g., max_files = {max_files}).

context:
  reasoning:
    - Keep the process straightforward and efficient:
      - Confirm scope and preferences with the user.
      - Use a single "create and run python script" to walk the directory tree, collect metadata, and write the inventory (and optional summary) in one pass.
    - Prefer CLI-based traversal using Python (os, os.path, datetime) to avoid GUI and unnecessary actions.
    - During traversal:
      - Apply include/exclude rules and optional size/age filters if provided.
      - For each file, collect path, name, extension, size, and modified timestamp.
      - Track simple counters (total files, total bytes) and optionally counts per extension.
    - After traversal:
      - Write the inventory to the chosen format at a clear workspace path like {inventory_file_path} (e.g., file_inventory_{timestamp}.csv).
      - If requested, write a short summary file {summary_file_path} (e.g., summary_{timestamp}.txt or .md).
      - Print a human-readable summary to stdout so the agent can easily present key numbers to the user.
    - Use minimal validation afterward:
      - Confirm that the generated file(s) exist.
      - Optionally inspect the first few lines using "shell view" or a quick Python check.
    - Do not modify the filesystem beyond creating the report files.
  deadline: {time_left} left until deadline {deadline}
  definition_of_done(check during final validation step):
    - At least one inventory file is successfully created at {inventory_file_path} in the workspace and is readable.
    - The inventory contains a non-zero number of entries if matching files exist (or zero with a clear explanation if no files matched filters).
    - No files under the root directories were renamed, moved, or deleted.
    - If aggregate stats were requested, they are present either in the inventory file or in a separate summary file {summary_file_path}.
    - The user receives a summary message that clearly states:
      - root paths processed
      - total file count
      - total size (e.g., in MB/GB)
      - where to find the report file(s).
  avoid:
    - Performing extra passes over the directory tree when one script run is enough.
    - Using GUI mode or additional tools that do not add clear value.
    - Automatically scanning entire drives (e.g., {system_drive}) without the user explicitly asking for it.
    - Modifying or deleting any existing files (other than creating the inventory/summary files).
    - Producing overly complex formats; stick to simple CSV/Markdown/JSON that are easy to reuse.

steps:
  name: Confirm inventory scope and output preferences
  description: Clarify what directory tree(s) to scan, how deep to go, and which report format to generate.
  action_instruction: >
    Use the "send_message" action to restate and confirm the key parameters:
    - Root directory path(s), e.g., {root_directory_1}, {root_directory_2}.
    - Whether to include subdirectories (recursive: true/false).
    - Desired output format: "csv" (default), "md", or "json".
    - Any include filters (e.g., only certain extensions or filenames containing {keyword}).
    - Any exclude filters (e.g., specific subfolders like {root_directory}\.git, or extensions like ".tmp").
    - Optional thresholds (min/max size, age filters) if the user cares.
    - Whether to compute a simple aggregate summary (true/false).
    - Any safety cap on files listed (e.g., "stop after {max_files} files").
    Ask the user to confirm or adjust these. If any critical detail is unclear (root path or format),
    use the "send_message" action with a focused question, e.g., "Which directory should I inventory?" or
    "Do you prefer CSV, Markdown, or JSON for the report?". Once answers are received, send a short "send_message"
    summarizing the final agreed parameters so they are recorded in the task history.
  validation_instruction: >
    Ensure that:
    - At least one root directory string {root_directory} is provided.
    - A valid output format has been chosen ("csv", "md", or "json"; default to "csv" if user does not care).
    - Recursion preference is known (treat as true by default if user does not object).
    If any of these are missing, use "send_message" once more. Proceed only after the user has clearly confirmed the scope and format.

  name: Generate file inventory and summary via script
  description: Traverse the directory tree(s) once, collect file metadata, and write an inventory file (and optional summary) to the workspace.
  action_instruction: >
    Use the "create and run python script" action with a single script that:
    - Encodes the agreed parameters:
      - root_paths = [{root_directory_1}, {root_directory_2}, ...]
      - recursive = {recursive_flag}
      - output_format = "{output_format}"  # "csv", "md", or "json"
      - include_extensions = [{include_extensions}] or None
      - exclude_extensions = [{exclude_extensions}] or None
      - exclude_paths = [{exclude_paths}] or None
      - min_size_bytes = {min_size_bytes} or None
      - max_size_bytes = {max_size_bytes} or None
      - older_than_days / newer_than_days as needed
      - compute_summary = {compute_summary_flag}
      - inventory_file_path = "{inventory_file_path}"  # e.g., file_inventory_{timestamp}.csv
      - summary_file_path = "{summary_file_path}"      # e.g., file_summary_{timestamp}.txt (optional)
    - For each root in root_paths:
      - Check that it exists and is a directory (os.path.isdir). If not, record a note in-memory and skip that root.
    - Traverse using os.walk when recursive is true; otherwise use os.listdir for the top-level only.
      - Optionally skip directories that match exclude_paths or obvious patterns the user has given.
    - For each file discovered:
      - Apply filters:
        - extension in include_extensions (if provided), and not in exclude_extensions.
        - path does not contain any excluded path substring (if provided).
        - size and age within any specified bounds.
      - If the file passes the filters:
        - Collect metadata:
          - full_path
          - file_name
          - extension
          - size_bytes (os.path.getsize)
          - modified_time (e.g., ISO format string from datetime.fromtimestamp).
        - Append this record to an in-memory list.
        - Update counting variables: total_files, total_size_bytes, extension_counts dict, etc.
    - After traversal:
      - Depending on output_format:
        - For "csv": write a CSV file with header "full_path,file_name,extension,size_bytes,modified_time" to inventory_file_path.
        - For "md": write a Markdown table with the same columns to inventory_file_path.
        - For "json": write a JSON list of objects to inventory_file_path.
      - If compute_summary is true:
        - Create a simple text/Markdown summary at summary_file_path containing:
          - Total roots visited.
          - Total valid files found.
          - Total size (with human-readable units).
          - Top N extensions by count and size, if desired.
      - Print a concise summary to stdout, for example:
        - "Roots visited: {n_roots}"
        - "Files listed: {total_files}"
        - "Total size: {total_size_bytes} bytes (~{total_size_human})"
        - "Inventory written to: {inventory_file_path}"
        - If created: "Summary written to: {summary_file_path}"
  validation_instruction: >
    Check the action output:
    - The script status should indicate success (no unhandled traceback).
    - stdout should mention the inventory_file_path and the total number of files listed.
    - If no files matched the filters and the user expected a non-empty result, send a short "send_message" explaining that
      the inventory is empty and suggest verifying the filters or path. The inventory file may still exist with only a header.
    - Optionally, if needed, use a quick follow-up "create and run python script" or "shell view" to:
      - Confirm the inventory file exists at {inventory_file_path}.
      - Inspect the first few rows/lines to ensure the structure is as expected.
    Proceed when the inventory file is confirmed to exist and is structurally reasonable.

  name: Overall validate inventory output
  description: Perform a simple final check that the inventory and (if requested) summary files meet the definition_of_done.
  action_instruction: >
    Perform minimal but sufficient validation using either "shell view" or a small "create and run python script":
    - Confirm that {inventory_file_path} exists and is non-empty (or contains at least a header line in the empty case).
    - If compute_summary was true, confirm that {summary_file_path} exists.
    - Optionally, count the number of data lines/rows in the inventory and compare with the total_files reported in stdout.
    - Ensure that no file-modifying operations were performed in the script (only reads and new report file writes).
    If the counts match and the files are present, treat the definition_of_done as satisfied. If there are mismatches or
    file creation failures, prepare to explain briefly to the user and decide whether a quick retry is appropriate or whether
    to fail the task with "mark task error".
  # No separate validation_instruction needed beyond these checks.

  name: Close task and report to user
  description: Summarize the inventory results for the user, provide paths to the report file(s), and mark the task status.
  action_instruction: >
    Use the "send_message" action to provide a concise summary, for example:
    - Root directory/ies processed: {root_directory_1}, {root_directory_2}, ...
    - Recursion: {recursive_flag}.
    - Output format: {output_format}.
    - Total files listed: {total_files}.
    - Total size (approximate in MB/GB): {total_size_human}.
    - Inventory file location: {inventory_file_path}.
    - If applicable, summary file location: {summary_file_path}.
    Mention explicitly that no original files were changed, only read and reported.
    Then:
    - If the task completed successfully according to the definition_of_done, call "mark task completed" with a brief message
      summarizing the inventory (e.g., "File inventory generated for {root_directory} with {total_files} files; report at {inventory_file_path}.").
    - If the user decided to change their mind and abort before running the script, call "mark task cancel" with the reason.
    - If the script failed repeatedly or the directory was not accessible and no meaningful inventory could be produced,
      call "mark task error" with a short explanation and any partial file paths if they exist.
