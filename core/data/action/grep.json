{
  "_id": { "$oid": "68b6ad213aa5a3e9d9026b9c" },
  "name": "grep",
  "description": "Searches a text file for keywords and returns matching chunks with pagination.",
  "type": "atomic",
  "execution_mode": "sandboxed",
  "mode": "CLI",
  "platforms": ["windows", "linux", "darwin"],
  "input_schema": {
    "input_file": {
      "type": "string",
      "example": "/path/to/input.txt",
      "description": "Absolute or relative path to the input text file to search. The file must already exist on disk and be readable as UTF-8 text (binary files are not supported)."
    },
    "keywords": {
      "type": "array",
      "example": ["Mt. Fuji", "visibility"],
      "description": "List of plain-text keywords to search for inside the file. All keywords are OR-ed together: a chunk is considered a match if it contains at least one of the keywords (case-insensitive). An empty list is not allowed.",
      "default": []
    },
    "chunk_size": {
      "type": "integer",
      "example": 300,
      "description": "Approximate number of words per chunk. The file content is first tokenized into words, then grouped into chunks of about chunk_size words. Larger values create bigger chunks (more context per hit but more tokens); smaller values create more, smaller chunks.",
      "default": 300
    },
    "overlap": {
      "type": "integer",
      "example": 50,
      "description": "Number of overlapping words between consecutive chunks. For example, with chunk_size=300 and overlap=50, the first chunk is words 1–300, the second chunk is words 251–550, etc.",
      "default": 50
    },
    "chunk_start": {
      "type": "integer",
      "example": 1,
      "description": "1-based start index of the matched chunk range to return (inclusive). If 0 or negative is provided, it is treated as 1.",
      "default": 1
    },
    "chunk_end": {
      "type": "integer",
      "example": 5,
      "description": "1-based end index of the matched chunk range to return (inclusive). If smaller than chunk_start, the two values will be swapped. If larger than the total number of matches, it will be clamped.",
      "default": 5
    }
  },
  "output_schema": {
    "chunks": {
      "type": "array",
      "example": [
        "[line 275] ...some text chunk...",
        "[line 937] ...another text chunk..."
      ],
      "description": "List of formatted chunks for the requested range."
    },
    "total_matches": {
      "type": "integer",
      "example": 23,
      "description": "Total number of matched chunks available."
    },
    "returned_range": {
      "type": "array",
      "example": [1, 5],
      "description": "The 1-based [start, end] chunk indices that were requested (clamped to available matches)."
    }
  },
  "scope": ["global"],
  "code": "raise NotImplementedError('Platform overrides are required')",
  "platform_overrides": {
    "linux": {
      "code": "import os, json, re, sys, asyncio\n\nasync def main():\n    input_file = input_data.get('input_file')\n    if not input_file or not os.path.isfile(input_file):\n        raise ValueError('Input file must exist.')\n\n    keywords = input_data.get('keywords') or []\n    if not keywords:\n        raise ValueError('keywords must be a non-empty array.')\n\n    try:\n        chunk_size = int(input_data.get('chunk_size', 300))\n    except Exception:\n        chunk_size = 300\n    try:\n        overlap = int(input_data.get('overlap', 50))\n    except Exception:\n        overlap = 50\n    try:\n        start_idx = int(input_data.get('chunk_start', 1))\n    except Exception:\n        start_idx = 1\n    try:\n        end_idx = int(input_data.get('chunk_end', 5))\n    except Exception:\n        end_idx = 5\n\n    if chunk_size <= 0:\n        chunk_size = 300\n    if overlap < 0:\n        overlap = 0\n\n    if start_idx < 1:\n        start_idx = 1\n    if end_idx < 1:\n        end_idx = 1\n    if end_idx < start_idx:\n        start_idx, end_idx = end_idx, start_idx\n\n    with open(input_file, 'r', encoding='utf-8', errors='ignore') as f:\n        content = f.read()\n\n    segments = chunk_text(content, chunk_size=chunk_size, overlap=overlap)\n\n    if not segments:\n        result = {'chunks': [], 'total_matches': 0, 'returned_range': [start_idx, end_idx]}\n        output = (json.dumps(result))\n        return\n\n    pattern = re.compile('(' + '|'.join(re.escape(k) for k in keywords) + ')', re.I)\n    matched_segments = [s for s in segments if pattern.search(s['text'])]\n\n    total_matches = len(matched_segments)\n    if total_matches == 0:\n        result = {'chunks': [], 'total_matches': 0, 'returned_range': [start_idx, end_idx]}\n        output = (json.dumps(result))\n        return\n\n    start_idx_clamped = max(1, min(start_idx, total_matches))\n    end_idx_clamped = max(1, min(end_idx, total_matches))\n    if end_idx_clamped < start_idx_clamped:\n        start_idx_clamped, end_idx_clamped = end_idx_clamped, start_idx_clamped\n\n    start_zero = start_idx_clamped - 1\n    end_zero_excl = end_idx_clamped\n\n    page_segments = matched_segments[start_zero:end_zero_excl]\n\n    def clean_text(s):\n        s = s.strip()\n        s = re.sub(r'\\s+', ' ', s)\n        return s\n\n    formatted_chunks = []\n    for seg in page_segments:\n        text_clean = clean_text(seg['text'])\n        if not text_clean:\n            continue\n        display_text = text_clean\n        if seg.get('has_leading_ellipsis'):\n            display_text = '...' + display_text\n        if seg.get('has_trailing_ellipsis'):\n            if not display_text.endswith('...'):\n                display_text = display_text + '...'\n        line_no = int(seg.get('start_word_index', 1))\n        para = f\"[line {line_no}] {display_text}\"\n        formatted_chunks.append(para)\n\n    result = {\n        'chunks': formatted_chunks,\n        'total_matches': total_matches,\n        'returned_range': [start_idx_clamped, end_idx_clamped]\n    }\n    output = (json.dumps(result))\n\n\ndef chunk_text(text, chunk_size=300, overlap=50):\n    import re as _re\n    words = _re.findall(r'\\S+', text or '')\n    if not words:\n        return []\n    if chunk_size <= 0:\n        chunk_size = 300\n    if overlap < 0:\n        overlap = 0\n    step = max(1, chunk_size - overlap)\n    n = len(words)\n    segments = []\n    for start in range(0, n, step):\n        end = min(start + chunk_size, n)\n        chunk_words = words[start:end]\n        if not chunk_words:\n            break\n        chunk_text_val = ' '.join(chunk_words).strip()\n        if not chunk_text_val:\n            continue\n        has_leading = start > 0\n        has_trailing = end < n\n        segments.append({\n            'text': chunk_text_val,\n            'start_word_index': start + 1,\n            'has_leading_ellipsis': bool(has_leading),\n            'has_trailing_ellipsis': bool(has_trailing)\n        })\n    return segments\n\nasyncio.run(main())"
    },
    "windows": {
      "code": "import os, json, re, sys, asyncio\n\nasync def main():\n    input_file = input_data.get('input_file')\n    if not input_file or not os.path.isfile(input_file):\n        raise ValueError('Input file must exist.')\n\n    keywords = input_data.get('keywords') or []\n    if not keywords:\n        raise ValueError('keywords must be a non-empty array.')\n\n    try:\n        chunk_size = int(input_data.get('chunk_size', 300))\n    except Exception:\n        chunk_size = 300\n    try:\n        overlap = int(input_data.get('overlap', 50))\n    except Exception:\n        overlap = 50\n    try:\n        start_idx = int(input_data.get('chunk_start', 1))\n    except Exception:\n        start_idx = 1\n    try:\n        end_idx = int(input_data.get('chunk_end', 5))\n    except Exception:\n        end_idx = 5\n\n    if chunk_size <= 0:\n        chunk_size = 300\n    if overlap < 0:\n        overlap = 0\n\n    if start_idx < 1:\n        start_idx = 1\n    if end_idx < 1:\n        end_idx = 1\n    if end_idx < start_idx:\n        start_idx, end_idx = end_idx, start_idx\n\n    with open(input_file, 'r', encoding='utf-8', errors='ignore') as f:\n        content = f.read()\n\n    segments = chunk_text(content, chunk_size=chunk_size, overlap=overlap)\n\n    if not segments:\n        result = {'chunks': [], 'total_matches': 0, 'returned_range': [start_idx, end_idx]}\n        output = (json.dumps(result))\n        return\n\n    pattern = re.compile('(' + '|'.join(re.escape(k) for k in keywords) + ')', re.I)\n    matched_segments = [s for s in segments if pattern.search(s['text'])]\n\n    total_matches = len(matched_segments)\n    if total_matches == 0:\n        result = {'chunks': [], 'total_matches': 0, 'returned_range': [start_idx, end_idx]}\n        output = (json.dumps(result))\n        return\n\n    start_idx_clamped = max(1, min(start_idx, total_matches))\n    end_idx_clamped = max(1, min(end_idx, total_matches))\n    if end_idx_clamped < start_idx_clamped:\n        start_idx_clamped, end_idx_clamped = end_idx_clamped, start_idx_clamped\n\n    start_zero = start_idx_clamped - 1\n    end_zero_excl = end_idx_clamped\n\n    page_segments = matched_segments[start_zero:end_zero_excl]\n\n    def clean_text(s):\n        s = s.strip()\n        s = re.sub(r'\\s+', ' ', s)\n        return s\n\n    formatted_chunks = []\n    for seg in page_segments:\n        text_clean = clean_text(seg['text'])\n        if not text_clean:\n            continue\n        display_text = text_clean\n        if seg.get('has_leading_ellipsis'):\n            display_text = '...' + display_text\n        if seg.get('has_trailing_ellipsis'):\n            if not display_text.endswith('...'):\n                display_text = display_text + '...'\n        line_no = int(seg.get('start_word_index', 1))\n        para = f\"[line {line_no}] {display_text}\"\n        formatted_chunks.append(para)\n\n    result = {\n        'chunks': formatted_chunks,\n        'total_matches': total_matches,\n        'returned_range': [start_idx_clamped, end_idx_clamped]\n    }\n    output = (json.dumps(result))\n\n\ndef chunk_text(text, chunk_size=300, overlap=50):\n    import re as _re\n    words = _re.findall(r'\\S+', text or '')\n    if not words:\n        return []\n    if chunk_size <= 0:\n        chunk_size = 300\n    if overlap < 0:\n        overlap = 0\n    step = max(1, chunk_size - overlap)\n    n = len(words)\n    segments = []\n    for start in range(0, n, step):\n        end = min(start + chunk_size, n)\n        chunk_words = words[start:end]\n        if not chunk_words:\n            break\n        chunk_text_val = ' '.join(chunk_words).strip()\n        if not chunk_text_val:\n            continue\n        has_leading = start > 0\n        has_trailing = end < n\n        segments.append({\n            'text': chunk_text_val,\n            'start_word_index': start + 1,\n            'has_leading_ellipsis': bool(has_leading),\n            'has_trailing_ellipsis': bool(has_trailing)\n        })\n    return segments\n\nasyncio.run(main())"
    },
    "darwin": {
      "code": "import os, json, re, sys, asyncio\n\nasync def main():\n    input_file = input_data.get('input_file')\n    if not input_file or not os.path.isfile(input_file):\n        raise ValueError('Input file must exist.')\n\n    keywords = input_data.get('keywords') or []\n    if not keywords:\n        raise ValueError('keywords must be a non-empty array.')\n\n    try:\n        chunk_size = int(input_data.get('chunk_size', 300))\n    except Exception:\n        chunk_size = 300\n    try:\n        overlap = int(input_data.get('overlap', 50))\n    except Exception:\n        overlap = 50\n    try:\n        start_idx = int(input_data.get('chunk_start', 1))\n    except Exception:\n        start_idx = 1\n    try:\n        end_idx = int(input_data.get('chunk_end', 5))\n    except Exception:\n        end_idx = 5\n\n    if chunk_size <= 0:\n        chunk_size = 300\n    if overlap < 0:\n        overlap = 0\n\n    if start_idx < 1:\n        start_idx = 1\n    if end_idx < 1:\n        end_idx = 1\n    if end_idx < start_idx:\n        start_idx, end_idx = end_idx, start_idx\n\n    with open(input_file, 'r', encoding='utf-8', errors='ignore') as f:\n        content = f.read()\n\n    segments = chunk_text(content, chunk_size=chunk_size, overlap=overlap)\n\n    if not segments:\n        result = {'chunks': [], 'total_matches': 0, 'returned_range': [start_idx, end_idx]}\n        output = (json.dumps(result))\n        return\n\n    pattern = re.compile('(' + '|'.join(re.escape(k) for k in keywords) + ')', re.I)\n    matched_segments = [s for s in segments if pattern.search(s['text'])]\n\n    total_matches = len(matched_segments)\n    if total_matches == 0:\n        result = {'chunks': [], 'total_matches': 0, 'returned_range': [start_idx, end_idx]}\n        output = (json.dumps(result))\n        return\n\n    start_idx_clamped = max(1, min(start_idx, total_matches))\n    end_idx_clamped = max(1, min(end_idx, total_matches))\n    if end_idx_clamped < start_idx_clamped:\n        start_idx_clamped, end_idx_clamped = end_idx_clamped, start_idx_clamped\n\n    start_zero = start_idx_clamped - 1\n    end_zero_excl = end_idx_clamped\n\n    page_segments = matched_segments[start_zero:end_zero_excl]\n\n    def clean_text(s):\n        s = s.strip()\n        s = re.sub(r'\\s+', ' ', s)\n        return s\n\n    formatted_chunks = []\n    for seg in page_segments:\n        text_clean = clean_text(seg['text'])\n        if not text_clean:\n            continue\n        display_text = text_clean\n        if seg.get('has_leading_ellipsis'):\n            display_text = '...' + display_text\n        if seg.get('has_trailing_ellipsis'):\n            if not display_text.endswith('...'):\n                display_text = display_text + '...'\n        line_no = int(seg.get('start_word_index', 1))\n        para = f\"[line {line_no}] {display_text}\"\n        formatted_chunks.append(para)\n\n    result = {\n        'chunks': formatted_chunks,\n        'total_matches': total_matches,\n        'returned_range': [start_idx_clamped, end_idx_clamped]\n    }\n    output = (json.dumps(result))\n\n\ndef chunk_text(text, chunk_size=300, overlap=50):\n    import re as _re\n    words = _re.findall(r'\\S+', text or '')\n    if not words:\n        return []\n    if chunk_size <= 0:\n        chunk_size = 300\n    if overlap < 0:\n        overlap = 0\n    step = max(1, chunk_size - overlap)\n    n = len(words)\n    segments = []\n    for start in range(0, n, step):\n        end = min(start + chunk_size, n)\n        chunk_words = words[start:end]\n        if not chunk_words:\n            break\n        chunk_text_val = ' '.join(chunk_words).strip()\n        if not chunk_text_val:\n            continue\n        has_leading = start > 0\n        has_trailing = end < n\n        segments.append({\n            'text': chunk_text_val,\n            'start_word_index': start + 1,\n            'has_leading_ellipsis': bool(has_leading),\n            'has_trailing_ellipsis': bool(has_trailing)\n        })\n    return segments\n\nasyncio.run(main())"
    }
  }
}
